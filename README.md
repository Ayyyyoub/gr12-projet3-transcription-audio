# Projet 3 : Syst√®me de Transcription Audio Automatis√©e avec Whisper et Streamlit

## üìù Projet r√©alis√© par : (Bin√¥me_12)
- ELGHIOUAN Ansam
- MAGHNOUJ Ayoub

## üìù Encadr√© par :
Pr. MAHMOUDI Abdelhak

## üîπ Description du projet
Ce projet est une application web de d√©monstration pour la transcription automatique de fichiers audio en texte. Elle utilise le puissant mod√®le **OpenAI Whisper** pour la reconnaissance vocale et une interface utilisateur interactive construite avec **Streamlit**. Ce document d√©taille son fonctionnement, son installation et son utilisation.

Ce projet est une application web de d√©monstration pour la transcription automatique de fichiers audio en texte. Elle utilise le puissant mod√®le **OpenAI Whisper** pour la reconnaissance vocale et une interface utilisateur interactive construite avec **Streamlit**. Ce document d√©taille son fonctionnement, son installation et son utilisation.

## üåü Fonctionnalit√©s Principales

-   **Upload Facile de Fichiers :** Permet aux utilisateurs de t√©l√©verser des fichiers audio dans des formats courants (MP3, WAV, M4A, OGG, FLAC).
-   **Transcription Automatique :** Utilise le mod√®le "base" d'OpenAI Whisper pour convertir la parole contenue dans l'audio en texte.
-   **D√©tection Automatique de la Langue :** Identifie la langue parl√©e dans le fichier audio et l'affiche.
-   **Interface Utilisateur Intuitive :** Interface simple et conviviale gr√¢ce √† Streamlit, guidant l'utilisateur √† travers le processus.
-   **Feedback en Temps R√©el :** Affiche une barre de progression pendant la transcription.
-   **Affichage Clair des R√©sultats :** Pr√©sente la transcription dans une zone de texte facile √† lire et √† copier.
-   **(Optionnel) D√©tails des Segments :** Possibilit√© d'afficher les segments de transcription avec leurs timestamps (via un expander).

## üõ†Ô∏è Technologies Utilis√©es

-   **Langage de Programmation :** Python 3.9+
-   **Mod√®le de Deep Learning :** OpenAI Whisper (mod√®le "base")
-   **Framework d'Interface Web :** Streamlit
-   **Gestion de l'Audio (implicite via Whisper) :** FFmpeg
-   **Gestion des D√©pendances :** pip, `requirements.txt`
-   **Contr√¥le de Version :** Git, GitHub

## üöÄ Pr√©requis et Installation

Avant de commencer, assurez-vous d'avoir les √©l√©ments suivants install√©s sur votre syst√®me :

1.  **Python :** Version 3.9 ou ult√©rieure. Vous pouvez le t√©l√©charger depuis [python.org](https://www.python.org/).
2.  **pip :** G√©n√©ralement inclus avec Python. V√©rifiez avec `pip --version`.
3.  **Git :** Pour cloner le d√©p√¥t. T√©l√©chargez depuis [git-scm.com](https://git-scm.com/).
4.  **FFmpeg :** **Crucial** pour le traitement audio par Whisper.
    -   **Linux (Debian/Ubuntu) :**
        ```bash
        sudo apt update && sudo apt install ffmpeg
        ```
    -   **macOS (avec Homebrew) :**
        ```bash
        brew install ffmpeg
        ```
    -   **Windows :**
        1.  T√©l√©chargez les binaires "release essentials" depuis [ffmpeg.org/download.html](https://ffmpeg.org/download.html) (cherchez les builds de gyan.dev ou BtbN).
        2.  D√©compressez l'archive (par exemple, dans `C:\ffmpeg`).
        3.  Ajoutez le dossier `bin` de FFmpeg (ex: `C:\ffmpeg\bin`) √† la variable d'environnement `PATH` de votre syst√®me.

### √âtapes d'Installation du Projet

1.  **Clonez ce d√©p√¥t GitHub :**
    ```bash
    git clone <URL_DE_VOTRE_DEPOT_GITHUB_ICI>
    cd projet_transcription_audio
    ```

2.  **Cr√©ez et activez un environnement virtuel Python (fortement recommand√©) :**
    ```bash
    python -m venv .venv
    ```
    -   Sur Linux/macOS :
        ```bash
        source .venv/bin/activate
        ```
    -   Sur Windows (Command Prompt) :
        ```bash
        .venv\Scripts\activate.bat
        ```
    -   Sur Windows (PowerShell) :
        ```bash
        .venv\Scripts\Activate.ps1
        ```
    Vous devriez voir `(.venv)` au d√©but de votre invite de commande.

3.  **Installez les d√©pendances Python :**
    ```bash
    pip install -r requirements.txt
    ```
    *Note : La premi√®re fois, cela peut prendre un certain temps pour t√©l√©charger les biblioth√®ques, y compris Whisper.*

## üèÉ Utilisation de l'Application

1.  Assurez-vous que votre environnement virtuel est activ√© et que FFmpeg est correctement install√© et accessible.
2.  Depuis le r√©pertoire racine du projet (`projet_transcription_audio`), lancez l'application Streamlit :
    ```bash
    streamlit run app.py
    ```
3.  Ouvrez votre navigateur web et acc√©dez √† l'URL affich√©e dans le terminal (g√©n√©ralement `http://localhost:8501`).
4.  L'interface de l'application s'affiche :
    *   Utilisez le widget "Choisissez un fichier audio" dans la barre lat√©rale pour uploader un fichier audio (ex: depuis le dossier `sample_audio/`).
    *   Une fois le fichier s√©lectionn√©, vous pouvez l'√©couter via le lecteur audio int√©gr√© dans la sidebar.
    *   Cliquez sur le bouton "Transcrire l'audio".
5.  Patientez pendant que la transcription est en cours (une barre de progression s'affichera).
6.  La transcription textuelle et la langue d√©tect√©e appara√Ætront dans la zone principale de l'application.

## üìÇ Structure du Projet
projet_transcription_audio/
‚îú‚îÄ‚îÄ .venv/ # Environnement virtuel Python (ignor√© par Git)
‚îú‚îÄ‚îÄ app.py # Script principal de l'application Streamlit
‚îú‚îÄ‚îÄ requirements.txt # Fichier listant les d√©pendances Python
‚îú‚îÄ‚îÄ sample_audio/ # Dossier pour les fichiers audio d'exemple
‚îÇ ‚îú‚îÄ‚îÄ exemple_francais_clair.mp3
‚îÇ ‚îî‚îÄ‚îÄ exemple_anglais_rapide.wav
‚îú‚îÄ‚îÄ .gitignore # Fichier sp√©cifiant les fichiers √† ignorer par Git
‚îî‚îÄ‚îÄ README.md # Ce fichier de documentation

-   `app.py`: Contient tout le code de l'application Streamlit, y compris le chargement du mod√®le, l'interface utilisateur et la logique de transcription.
-   `requirements.txt`: D√©finit les biblioth√®ques Python n√©cessaires au projet.
-   `sample_audio/`: Comprend quelques fichiers audio pour tester rapidement l'application.
-   `.gitignore`: Indique √† Git quels fichiers ou dossiers ignorer.
-   `README.md`: Fournit une vue d'ensemble compl√®te du projet.

## üñºÔ∏è Captures d'√âcran de la D√©mo

*(Ins√©rer ici 2-3 captures d'√©cran claires de l'application en fonctionnement)*

**Figure 1 : Interface principale apr√®s le lancement.**
![Interface Principale](URL_OU_CHEMIN_VERS_CAPTURE_ECRAN_1.png)

**Figure 2 : Fichier audio upload√© et pr√™t pour la transcription.**
![Fichier Upload√©](URL_OU_CHEMIN_VERS_CAPTURE_ECRAN_2.png)

**Figure 3 : R√©sultat de la transcription affich√©.**
![R√©sultat Transcription](URL_OU_CHEMIN_VERS_CAPTURE_ECRAN_3.png)

## üìπ Vid√©o de Pr√©sentation

Une vid√©o de pr√©sentation d√©taill√©e (max 7 minutes) expliquant l'environnement, le code et la d√©mo de l'application est disponible ici :
[Lien vers la vid√©o de pr√©sentation (YouTube, Vimeo, ou fichier dans Google Drive)](LIEN_VERS_LA_VIDEO_ICI)

*(Si la vid√©o est embarqu√©e dans le Google Drive, le lien du Google Drive principal suffit)*

## ‚ö†Ô∏è Probl√®mes Connus et Limitations

-   La transcription de fichiers audio tr√®s longs ou de tr√®s grande taille peut √™tre lente et consommer beaucoup de m√©moire, surtout avec le mod√®le "base" sur CPU.
-   La pr√©cision peut diminuer en pr√©sence de bruits de fond importants, de multiples locuteurs parlant simultan√©ment, ou d'un jargon tr√®s sp√©cifique non pr√©sent dans les donn√©es d'entra√Ænement de Whisper.
-   Le premier lancement de l'application peut √™tre plus long car le mod√®le Whisper doit √™tre t√©l√©charg√©.
-   L'application est actuellement limit√©e par les capacit√©s de la machine sur laquelle elle tourne (CPU/GPU, RAM).

## üí° Pistes d'Am√©lioration Futures

-   Permettre √† l'utilisateur de choisir la taille du mod√®le Whisper (tiny, base, small, etc.) pour un compromis vitesse/pr√©cision.
-   Int√©grer la possibilit√© d'enregistrer l'audio directement depuis le navigateur.
-   Ajouter des options de post-traitement du texte (ex: formatage, suppression des h√©sitations).
-   D√©ployer l'application sur une plateforme plus robuste pour une utilisation √† plus grande √©chelle (ex: Docker sur un VPS, services cloud).
-   Afficher des m√©triques plus d√©taill√©es sur la transcription (ex: score de confiance par segment).

---
*Ce projet a √©t√© r√©alis√© dans le cadre du "Projet 3 - End-to-End Deep Learning".*